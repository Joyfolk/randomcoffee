# Telegram Random Coffee scripts

A set of scripts which automate the selection of the people for the random coffee chats based on their self-introductions.
The system consists of three scripts that could be used together or separately:

1. `get_intro.py` - Fetches introduction messages from a Telegram group
2. `generate_embeddings.py` - Converts introductions into embeddings
3. `create_pairs.py` - Creates optimal random coffee pairs and generates personalized messages

`get_intro.py` checks the group chat and downloads all messages with specified tag (for example `#Intro`)
as text files. The reference to the original message in the Telegram is stored as the first line in the file.

`generate_embeddings.py` generates a json-file with the embeddings from the introductions by using special LLM models. 
The next script uses these embeddings to create random coffee pairs.

`create_pairs.py` creates random-coffee pairs as a csv file. It uses embeddings, generated by `generate_embeddings.py`
to calculate similarity score between the users, and maximum weight matching algorithm to create optimal pairs.
To avoid determinism, a small randomness is added. Also, it is possible to have several rounds of random coffees.
To support that, the script checks all previously generated pairs and avoids duplicate meetings.

So, the basic usage sequence:
1. Download intros with `get_intro.py`.
2. Generate embeddings for these intros with `generate_embeddings.py`
3. Create random coffee as many times as you want with `create_pairs.py`

Please keep in mind that these scripts are experimental and shouldn't be taken too seriously.

## Setup

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Register Telegram Application

1. Go to [Telegram API development tools](https://my.telegram.org/apps)
2. Create a new application and note down your API ID and API Hash
3. Create a `.env` file based on `.env.example` and add your credentials:

```
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash
```

### 3. Set Up OpenAI API Key

For generating embeddings and pairing messages, you'll need an OpenAI API key or compatible alternative:

1. Get an API key from [OpenAI](https://platform.openai.com/account/api-keys)
2. Add it to your `.env` file (or just set values as environment variables):

```
OPENAI_API_KEY=your_api_key_here
OPENAI_API_BASE_URL=https://api.studio.nebius.ai/v1

# Model configurations
EMBEDDING_MODEL=text-embedding-3-small
CHAT_MODEL=gpt-4
```

You could use other LLM models with OpenAI compatible API as well. Just update the variables accordingly.

## Scripts usage

### `get_intro.py` 

```bash
python get_intro.py --group GROUP_ID [--thread THREAD_ID] [--tag HASHTAG] [--output OUTPUT_DIR]
```

#### Parameters for get_intro.py

- `--group` or `-g`: Group ID (e.g., 1234567890, check the telegram client for that)
- `--thread` or `-t`: (Optional) Thread/topic ID to search within (for groups with topics)
- `--tag`: Hashtag to filter messages (default: #Intro)
- `--session` or `-s`: Name of the session file (default: session)
- `--output` or `-o`: Directory to save intro files (default: data/intros)

#### Notes about get_intro.py

- You must be a member of the group to fetch messages
- For each user, only their most recent post with the specified tag is saved
- Messages are saved as text files named after the username (e.g., `username.txt`)
- Each file contains the message link on the first line and the intro text on the following lines

### `generate_embeddings.py`

```bash
python generate_embeddings.py [--input INPUT_DIR] [--output OUTPUT_FILE] [--model MODEL_NAME] [--base-url API_URL]
```

#### Parameters for generate_embeddings.py

- `--input` or `-i`: Directory containing intro files (default: data/intros)
- `--output` or `-o`: Output file for embeddings (default: data/embeddings.json)
- `--model` or `-m`: Embedding model to use (default: from EMBEDDING_MODEL env var or text-embedding-3-small)
- `--base-url` or `-b`: API base URL (default: from OPENAI_API_BASE_URL env var or OpenAI API)

#### Notes about generate_embeddings.py

- This script processes each intro file and generates a semantic embedding vector
- Embeddings are stored in a JSON file that includes user information and embedding vectors
- You can use alternative embedding models by specifying them in the command or .env file
- If using a service other than OpenAI, set the appropriate base URL

### `create_pairs.py`

```bash
python create_pairs.py [--embeddings EMBEDDINGS_FILE] [--output OUTPUT_FILE] [--randomness FACTOR] [--model MODEL_NAME] [--pairs-dir PAIRS_DIR] [--templates-dir TEMPLATES_DIR]
```

#### Parameters for create_pairs.py

- `--embeddings` or `-e`: Embeddings file (default: data/embeddings.json)
- `--randomness` or `-r`: Randomness factor (default: 0.2)
- `--model` or `-m`: LLM model for generating pairing messages (default: from CHAT_MODEL env var or gpt-4)
- `--pairs-dir`: Directory for storing pairing history CSV files (default: data/pairs)
- `--templates-dir`: Directory containing prompt templates (default: templates)

#### Notes about create_pairs.py

- The system creates pairs based on semantic similarity with a randomness factor
- For each pair, a personalized introduction message is generated
- Pairing history is stored to avoid repeating the same pairs in future runs
- The script generates a CSV file with the pairings and messages

## Customization

### Templates

You can customize the message generation by editing the template files in the `templates` directory:

- `system_prompt.txt`: Sets the system instruction for the LLM
- `pairing_message.txt`: Template for generating the pairing messages

### Adjusting Pairing Algorithm

You can tune the pairing algorithm by adjusting:

- **Randomness Factor**: Higher values (0.3-0.5) create more diverse pairings, while lower values (0.1-0.2) prioritize similarity
- **Pairing History**: The system automatically avoids recent pairings, but you can reset history by clearing the `data/pairs` directory

## Notes

This project was mostly vibe-coded, so no guarantees on quality. Use at your own risk!